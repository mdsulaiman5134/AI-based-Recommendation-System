{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load u.data\n",
    "ratings = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", False).csv(\"/FileStore/tables/u.data\")\n",
    "ratings = ratings.withColumnRenamed(\"_c0\", \"user_id\")\\\n",
    ".withColumnRenamed(\"_c1\", \"movie_id\")\\\n",
    ".withColumnRenamed(\"_c2\", \"rating\")\\\n",
    ".withColumnRenamed(\"_c3\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a612be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load u.item (encoding issue fix: ISO-8859-1)\n",
    "movies = spark.read.option(\"delimiter\", \"|\").option(\"header\", False)\\\n",
    ".csv(\"/FileStore/tables/u.item\", encoding=\"ISO-8859-1\")\n",
    "movies = movies.selectExpr(\"_c0 as movie_id\", \"_c1 as title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b58398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample data\n",
    "ratings.show(5)\n",
    "movies.show(5)\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "# Convert types\n",
    "ratings = ratings.select(\n",
    "col(\"user_id\").cast(\"int\"),\n",
    "col(\"movie_id\").cast(\"int\"),\n",
    "col(\"rating\").cast(\"float\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125083b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "als = ALS(\n",
    "userCol=\"user_id\",\n",
    "itemCol=\"movie_id\",\n",
    "ratingCol=\"rating\",\n",
    "nonnegative=True,\n",
    "coldStartStrategy=\"drop\", Â # handles NaN predictions\n",
    "implicitPrefs=False,\n",
    "rank=10,\n",
    "maxIter=10,\n",
    "regParam=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac550b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "metricName=\"rmse\",\n",
    "labelCol=\"rating\",\n",
    "predictionCol=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "# Top 5 movie recommendations for all users\n",
    "user_recs = model.recommendForAllUsers(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show recommendations for a specific user (e.g., user_id = 100)\n",
    "user_recs.filter(user_recs.user_id == 100).show(truncate=False)\n",
    "# Load u.item (movie metadata)\n",
    "movies_raw = spark.read.text(\"/FileStore/tables/u.item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa73145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u.item is pipe-delimited, and contains:\n",
    "# movie_id | title | release_date | video_release | IMDb URL | genres (19 binary columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.option(\"delimiter\", \"|\").csv(\n",
    "\"/FileStore/tables/u.item\",\n",
    "inferSchema=True\n",
    ").toDF(\"movie_id\", \"title\", \"release_date\", \"video_release_date\", \"IMDb_URL\",\n",
    "\"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "\"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "\"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array, concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14083c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine genre columns\n",
    "genre_columns = [\"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "\"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n",
    "\"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\",\n",
    "\"Thriller\", \"War\", \"Western\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.withColumn(\"genres\",\n",
    "concat_ws(\" \",\n",
    "*[col(c).cast(\"string\") for c in genre_columns if c in movies.columns]\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"genres\", outputCol=\"words\")\n",
    "words_data = tokenizer.transform(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3df43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"raw_features\", numFeatures=100)\n",
    "featurized_data = hashingTF.transform(words_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idf_model = idf.fit(featurized_data)\n",
    "tfidf_data = idf_model.transform(featurized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fcd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\"/dbfs/FileStore/tables\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43adf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the CSV\n",
    "# Save to a community-accessible path\n",
    "final_recs.toPandas().to_csv(\"/dbfs/FileStore/tables/als_recommendations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ALS recommendations\n",
    "user_recommendations = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode to flat structure\n",
    "from pyspark.sql.functions import explode\n",
    "flat_recs = user_recommendations.select(\"user_id\", explode(\"recommendations\").alias(\"rec\"))\n",
    "flat_recs = flat_recs.select(\"user_id\", col(\"rec.movie_id\"), col(\"rec.rating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7daf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with movie titles\n",
    "final_recs = flat_recs.join(movies.select(\"movie_id\", \"title\"), on=\"movie_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as CSV\n",
    "# Save to a community-accessible path\n",
    "final_recs.toPandas().to_csv(\"/dbfs/FileStore/tables/als_recommendations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ALS recommendations as CSV using Spark (not Pandas)\n",
    "final_recs.write \\\n",
    ".mode(\"overwrite\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".csv(\"dbfs:/FileStore/tables/als_recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the partitioned files\n",
    "merged_df = spark.read.csv(\"dbfs:/FileStore/tables/als_recommendations/\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a single CSV\n",
    "merged_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"dbfs:/FileStore/als_recommendations_merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"dbfs:/FileStore/als_recommendations_merged\"))\n",
    "# Generate a downloadable link\n",
    "displayHTML(f\"<a href='/files/als_recommendations_merged/part-00000-tid-6547586960507395759-25303109-f205-42cd-923f-0db5e5132b54-1765-1-c000.csv'>Download CSV</a>\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
